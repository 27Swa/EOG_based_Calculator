# EOG-Based Calculator ğŸ‘ï¸ğŸ§®

This project implements a calculator that can be controlled using **EOG (Electrooculography) signals**. Itâ€™s designed to assist individuals with motor impairments by enabling calculations through eye movements.

---

### ğŸ§  Project Overview

We built a machine learning pipeline to classify EOG-based eye gestures and used these gestures to control a **GUI calculator**. The interface is built using **Tkinter**, and we used **Streamlit** for deployment.

---

### ğŸ” Key Features

- âœ… Eye gesture recognition using EOG signals from `.txt` files
- âœ… ML model trained to classify eye movements (e.g., left, right, blink)
- âœ… Saved model in `.pkl` format for reuse
- âœ… GUI built with **Tkinter**
- âœ… Deployment and automation with **Streamlit**

---

### ğŸ§ª AI & Model Training

Implemented in `EOG2.ipynb`:

- **Input Format:** EOG signals loaded from `.txt` files
- **Preprocessing:** Cleaning and preparing EOG data
- **Feature Extraction:** Statistical features from eye movements
- **Model Training:** Supervised classification (e.g., Random Forest / SVM)
- **Evaluation:** Accuracy metrics and confusion matrix
- **Model Saving:** Exported using `joblib

> ğŸ“ `model.pkl` â€“ the trained classifier used in deployment

---

### ğŸ–¥ï¸ GUI & Deployment

#### ğŸ¨ GUI with Tkinter

A calculator interface built with Pythonâ€™s `tkinter`:

- Visual buttons and display
- Gesture-based navigation and selection
- Integrated with the trained model for real-time interaction

#### ğŸš€ Deployment Using Streamlit

used to automate deployment and simulate user input:

- Load model and predict gestures
- Automate calculator interaction based on predictions
- Test automation and functional verification

---
